{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4add6411-586a-472a-ab84-929e29c13899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56805f90-6d9a-4299-a537-7d2c60fd52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZE = 1024\n",
    "OUTPUT_SIZE = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "MOMENTUM = 0.9\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 28\n",
    "TRAIN_SPLIT = 0.001\n",
    "PRINT_INTERVAL = 1000\n",
    "RAND_MAX = 32767\n",
    "\n",
    "TRAIN_IMG_PATH = \"data/train-images.idx3-ubyte\"\n",
    "TRAIN_LBL_PATH = \"data/train-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a83c0c0-673c-46bc-9943-b76a0185b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = [0.0] * (input_size * output_size)  # Placeholder initialization\n",
    "        self.biases = [0.0] * output_size\n",
    "        self.weight_momentum = [0.0] * (input_size * output_size)\n",
    "        self.bias_momentum = [0.0] * output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316a9fd1-2083-43fe-ac7c-e1780bb2dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, hidden_input_size, hidden_output_size, output_input_size, output_output_size):\n",
    "        self.hidden = Layer(hidden_input_size, hidden_output_size)\n",
    "        self.output = Layer(output_input_size, output_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3b538d-bfe7-4e3f-bf79-173d11f31ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputData:\n",
    "    def __init__(self, images, labels, count):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.count = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3599170b-edd4-4316-a65f-89840ae5f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def init_layer(layer: Layer, in_size: int, out_size: int):\n",
    "    scale = math.sqrt(2.0 / in_size)\n",
    "    layer = Layer(in_size, out_size)\n",
    "\n",
    "    for i in range(0, (in_size * out_size)):\n",
    "        layer.weights[i] = (random.random() / RAND_MAX - 0.5) * 2 * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5918cc-1636-4aee-bece-82cfaff335aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_images(filename, image_size):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        # Read and ignore the first integer (`temp`)\n",
    "        temp = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read number of images\n",
    "        n_images = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read number of rows and columns, ensuring byte swap with big-endian format\n",
    "        rows = struct.unpack('>i', file.read(4))[0]\n",
    "        cols = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read raw pixel data for all images\n",
    "        images_data = file.read(n_images * image_size * image_size)\n",
    "    \n",
    "    # Convert raw data to numpy array of the appropriate shape\n",
    "    images_array = np.frombuffer(images_data, dtype=np.uint8)\n",
    "    # images_array = images_array.reshape((n_images, image_size, image_size))\n",
    "    \n",
    "    return n_images, rows, cols, images_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b7e5b2-60e3-4fb8-9c8e-a6c1e9283110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_labels(filename):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        # Read and ignore the first integer (`temp`)\n",
    "        temp = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read number of images\n",
    "        n_labels = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read raw pixel data for all images\n",
    "        labels_data = file.read(n_labels)\n",
    "    \n",
    "    # Convert raw data to numpy array of the appropriate shape\n",
    "    labels_array = np.frombuffer(labels_data, dtype=np.uint8)\n",
    "    # labels_array = labels_array.reshape((n_labels))\n",
    "    \n",
    "    return n_labels, labels_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9eccfb-6320-4736-87cb-9e551d4a4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def shuffle_data(images, labels, n: int):\n",
    "    for i in range(n - 1, 0):\n",
    "        j = random.randint(i, INPUT_SIZE)\n",
    "        for k in range(0, INPUT_SIZE):\n",
    "            temp = images[i * INPUT_SIZE + k]\n",
    "            images[i * INPUT_SIZE + k] = images[j * INPUT_SIZE + k]\n",
    "            images[j * INPUT_SIZE + k] = temp\n",
    "\n",
    "        temp = labels[i]\n",
    "        labels[i] = labels[j]\n",
    "        labels[j] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f75b77b-4eee-4eb2-a801-29e3a2c22530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "\n",
    "def softmax(input, size):\n",
    "    output = numpy.exp(input) / numpy.sum(numpy.exp(input))\n",
    "    return output\n",
    "\n",
    "# def softmax(input, size):\n",
    "#     # print(\"softmax\")\n",
    "#     max = input[0]\n",
    "#     sum = 0\n",
    "\n",
    "#     for i in range (1, size):\n",
    "#         if input[i] > max:\n",
    "#             max = input[i]\n",
    "        \n",
    "#     for i in range(0, size):\n",
    "#         input[i] = math.exp(input[i] - max)\n",
    "#         sum += input[i]\n",
    "    \n",
    "#     for i in range(0, size):\n",
    "#         input[i] /= sum\n",
    "\n",
    "#     return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714557a0-cbf2-4d2a-a3d7-126770a7cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(layer: Layer, input, output):\n",
    "    # print(\"forward\")\n",
    "    for i in range(0, layer.output_size):\n",
    "        output[i] = layer.biases[i]\n",
    "\n",
    "    for j in range(0, layer.input_size):\n",
    "        in_j = input[j]\n",
    "        for i in range(0, layer.output_size):\n",
    "            output[i] += in_j * layer.weights[(j * layer.output_size) + i]\n",
    "\n",
    "    for i in range(0, layer.output_size):\n",
    "        output[i] = output[i] if output[i] > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc1e834-007b-4d9d-a1af-15fcd00f3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(layer: Layer, input, output_grad, input_grad, lr):\n",
    "    # print(\"backward\")\n",
    "    if (input_grad):\n",
    "        for j in range(0, layer.input_size):\n",
    "            input_grad[j] = 0.0\n",
    "            for i in range(0, layer.output_size):\n",
    "                input_grad[j] += output_grad[i] * layer.weights[(j * layer.output_size) + i]\n",
    "\n",
    "    for j in range(0, layer.input_size):\n",
    "        in_j = input[j]\n",
    "        for i in range(0, layer.output_size):\n",
    "            grad = output_grad[i] * in_j\n",
    "            layer.weight_momentum[(j * layer.output_size) + i] = MOMENTUM * layer.weight_momentum[(j * layer.output_size) + i] + lr * grad\n",
    "            layer.weights[(j * layer.output_size) + i] -= layer.weight_momentum[(j * layer.output_size) + i]\n",
    "            if (input_grad):\n",
    "                input_grad[j] += output_grad[i] * layer.weights[(j * layer.output_size) + i]\n",
    "\n",
    "    for i in range(0, layer.output_size):\n",
    "        layer.bias_momentum[i] = MOMENTUM * layer.bias_momentum[i] + lr * output_grad[i]\n",
    "        layer.biases[i] -= layer.bias_momentum[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb9019d-069d-450c-aa8f-e5fe7a8a3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net: Network, input, label, lr):\n",
    "    # print(\"train\")\n",
    "    final_output = [0] * OUTPUT_SIZE\n",
    "    hidden_output= [0] * HIDDEN_SIZE\n",
    "    output_grad = [0] * OUTPUT_SIZE\n",
    "    hidden_grad = [0] * HIDDEN_SIZE\n",
    "\n",
    "    forward(net.hidden, input, hidden_output)\n",
    "    forward(net.output, hidden_output, final_output)\n",
    "    final_output = softmax(final_output, OUTPUT_SIZE)\n",
    "\n",
    "    for i in range(0, OUTPUT_SIZE):\n",
    "        output_grad[i] = final_output[i] - (i == label)\n",
    "\n",
    "    backward(net.output, hidden_output, output_grad, hidden_grad, lr)\n",
    "\n",
    "    for i in range(0, HIDDEN_SIZE):\n",
    "        hidden_grad[i] *= 1 if hidden_output[i] > 0 else 0 # ReLU derivative\n",
    "\n",
    "    backward(net.hidden, input, hidden_grad, False, lr)\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6057237-bb49-4426-b26c-a6ba28da4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net: Network, input):\n",
    "    final_output = [0] * OUTPUT_SIZE\n",
    "    hidden_output= [0] * HIDDEN_SIZE\n",
    "\n",
    "    forward(net.hidden, input, hidden_output)\n",
    "    forward(net.output, hidden_output, final_output)\n",
    "    final_output = softmax(final_output, OUTPUT_SIZE)\n",
    "    \n",
    "    max_index = 0\n",
    "    for i in range (1, OUTPUT_SIZE):\n",
    "        if final_output[i] > final_output[max_index]:\n",
    "            max_index = i\n",
    "\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a2e7e8-c55b-4444-a41b-9e0f35314cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__():\n",
    "    print(\"__init__\")\n",
    "    net = Network(INPUT_SIZE, HIDDEN_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    \n",
    "    init_layer(net.hidden, INPUT_SIZE, HIDDEN_SIZE);\n",
    "    init_layer(net.output, HIDDEN_SIZE, OUTPUT_SIZE);\n",
    "\n",
    "    (n_images, rows, cols, images_array) = load_images('./data/train-images.idx3-ubyte', IMAGE_SIZE)\n",
    "    (n_labels, labels_array) = load_labels('./data/train-labels.idx1-ubyte')\n",
    "\n",
    "    data = InputData(images_array, labels_array, n_images)\n",
    "    shuffle_data(data.images, data.labels, data.count)\n",
    "\n",
    "    learning_rate = LEARNING_RATE\n",
    "    img = [0] * INPUT_SIZE\n",
    "\n",
    "    train_size = 200 # int(data.count * TRAIN_SPLIT)\n",
    "    test_size = 100 # int(data.count - train_size)\n",
    "\n",
    "    for epoch in range (0, EPOCHS):\n",
    "        total_loss = 0\n",
    "        for i in range(0, train_size):\n",
    "            for k in range(0, INPUT_SIZE):\n",
    "                # print(i,k)\n",
    "                img[k] = data.images[i * INPUT_SIZE + k] / 255.0\n",
    "\n",
    "            final_output = train(net, img, data.labels[i], learning_rate)\n",
    "            total_loss += -math.log(final_output[data.labels[i]] + 0.0000000001)\n",
    "    \n",
    "        correct = 0\n",
    "        for i in range(train_size, train_size + test_size):\n",
    "            for k in range(0, INPUT_SIZE):\n",
    "                img[k] = data.images[i * INPUT_SIZE + k] / 255.0\n",
    "            if predict(net, img) == data.labels[i]:\n",
    "                correct += 1\n",
    "    \n",
    "        print(\"Epoch {}, Train {}, Test {}, Correct {}, Loss {}\".format(epoch + 1, train_size, test_size, correct, total_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60a8f478-8e66-42ae-8cfc-efb49e041552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n",
      "Epoch 1, Train 200, Test 100, Correct 13, Loss 460.6303475586824\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[0;32mIn[15], line 27\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, INPUT_SIZE):\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m# print(i,k)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         img[k] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mimages[i \u001b[38;5;241m*\u001b[39m INPUT_SIZE \u001b[38;5;241m+\u001b[39m k] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m---> 27\u001b[0m     final_output \u001b[38;5;241m=\u001b[39m train(net, img, data\u001b[38;5;241m.\u001b[39mlabels[i], learning_rate)\n\u001b[1;32m     28\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(final_output[data\u001b[38;5;241m.\u001b[39mlabels[i]] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0000000001\u001b[39m)\n\u001b[1;32m     30\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, input, label, lr)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, HIDDEN_SIZE):\n\u001b[1;32m     18\u001b[0m     hidden_grad[i] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hidden_output[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# ReLU derivative\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m backward(net\u001b[38;5;241m.\u001b[39mhidden, \u001b[38;5;28minput\u001b[39m, hidden_grad, \u001b[38;5;28;01mFalse\u001b[39;00m, lr)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_output\n",
      "Cell \u001b[0;32mIn[12]\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(layer, input, output_grad, input_grad, lr)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a84feb-73ec-4a3e-a75e-939f80691d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86aaedc-e6c3-49ac-a39f-8842ba725eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
