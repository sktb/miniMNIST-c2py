{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4add6411-586a-472a-ab84-929e29c13899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56805f90-6d9a-4299-a537-7d2c60fd52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 784\n",
    "HIDDEN_SIZE = 1024\n",
    "OUTPUT_SIZE = 10\n",
    "LEARNING_RATE = 0.0005\n",
    "MOMENTUM = 0.9\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 28\n",
    "TRAIN_SPLIT = 0.001\n",
    "PRINT_INTERVAL = 1000\n",
    "RAND_MAX = 32767\n",
    "\n",
    "TRAIN_IMG_PATH = \"data/train-images.idx3-ubyte\"\n",
    "TRAIN_LBL_PATH = \"data/train-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a83c0c0-673c-46bc-9943-b76a0185b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = [0.0] * (input_size * output_size)  # Placeholder initialization\n",
    "        self.biases = [0.0] * output_size\n",
    "        self.weight_momentum = [0.0] * (input_size * output_size)\n",
    "        self.bias_momentum = [0.0] * output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "316a9fd1-2083-43fe-ac7c-e1780bb2dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, hidden_input_size, hidden_output_size, output_input_size, output_output_size):\n",
    "        self.hidden = Layer(hidden_input_size, hidden_output_size)\n",
    "        self.output = Layer(output_input_size, output_output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3b538d-bfe7-4e3f-bf79-173d11f31ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputData:\n",
    "    def __init__(self, images, labels, count):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.count = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3599170b-edd4-4316-a65f-89840ae5f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def init_layer(layer: Layer, in_size: int, out_size: int):\n",
    "    scale = math.sqrt(2.0 / in_size)\n",
    "    layer = Layer(in_size, out_size)\n",
    "\n",
    "    for i in range(0, (in_size * out_size)):\n",
    "        layer.weights[i] = (random.random() / RAND_MAX - 0.5) * 2 * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5918cc-1636-4aee-bece-82cfaff335aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_images(filename, image_size):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        # Read and ignore the first integer (`temp`)\n",
    "        temp = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read number of images\n",
    "        n_images = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read number of rows and columns, ensuring byte swap with big-endian format\n",
    "        rows = struct.unpack('>i', file.read(4))[0]\n",
    "        cols = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read raw pixel data for all images\n",
    "        images_data = file.read(n_images * image_size * image_size)\n",
    "    \n",
    "    # Convert raw data to numpy array of the appropriate shape\n",
    "    images_array = np.frombuffer(images_data, dtype=np.uint8)\n",
    "    # images_array = images_array.reshape((n_images, image_size, image_size))\n",
    "    \n",
    "    return n_images, rows, cols, images_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b7e5b2-60e3-4fb8-9c8e-a6c1e9283110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def load_labels(filename):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        # Read and ignore the first integer (`temp`)\n",
    "        temp = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read number of images\n",
    "        n_labels = struct.unpack('>i', file.read(4))[0]\n",
    "        \n",
    "        # Read raw pixel data for all images\n",
    "        labels_data = file.read(n_labels)\n",
    "    \n",
    "    # Convert raw data to numpy array of the appropriate shape\n",
    "    labels_array = np.frombuffer(labels_data, dtype=np.uint8)\n",
    "    # labels_array = labels_array.reshape((n_labels))\n",
    "    \n",
    "    return n_labels, labels_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9eccfb-6320-4736-87cb-9e551d4a4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def shuffle_data(images, labels, n: int):\n",
    "    for i in range(n - 1, 0):\n",
    "        j = random.randint(i, INPUT_SIZE)\n",
    "        for k in range(0, INPUT_SIZE):\n",
    "            temp = images[i * INPUT_SIZE + k]\n",
    "            images[i * INPUT_SIZE + k] = images[j * INPUT_SIZE + k]\n",
    "            images[j * INPUT_SIZE + k] = temp\n",
    "\n",
    "        temp = labels[i]\n",
    "        labels[i] = labels[j]\n",
    "        labels[j] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f75b77b-4eee-4eb2-a801-29e3a2c22530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "\n",
    "def softmax(input, size):\n",
    "    output = numpy.exp(input) / numpy.sum(numpy.exp(input))\n",
    "    return output\n",
    "\n",
    "# def softmax(input, size):\n",
    "#     # print(\"softmax\")\n",
    "#     max = input[0]\n",
    "#     sum = 0\n",
    "\n",
    "#     for i in range (1, size):\n",
    "#         if input[i] > max:\n",
    "#             max = input[i]\n",
    "        \n",
    "#     for i in range(0, size):\n",
    "#         input[i] = math.exp(input[i] - max)\n",
    "#         sum += input[i]\n",
    "    \n",
    "#     for i in range(0, size):\n",
    "#         input[i] /= sum\n",
    "\n",
    "#     return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714557a0-cbf2-4d2a-a3d7-126770a7cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(layer: Layer, input, output):\n",
    "    # print(\"forward\")\n",
    "    for i in range(0, layer.output_size):\n",
    "        output[i] = layer.biases[i]\n",
    "\n",
    "    for j in range(0, layer.input_size):\n",
    "        in_j = input[j]\n",
    "        for i in range(0, layer.output_size):\n",
    "            output[i] += in_j * layer.weights[(j * layer.output_size) + i]\n",
    "\n",
    "    for i in range(0, layer.output_size):\n",
    "        output[i] = output[i] if output[i] > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc1e834-007b-4d9d-a1af-15fcd00f3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(layer: Layer, input, output_grad, input_grad, lr):\n",
    "    # print(\"backward\")\n",
    "    if (input_grad):\n",
    "        for j in range(0, layer.input_size):\n",
    "            input_grad[j] = 0.0\n",
    "            for i in range(0, layer.output_size):\n",
    "                input_grad[j] += output_grad[i] * layer.weights[(j * layer.output_size) + i]\n",
    "\n",
    "    for j in range(0, layer.input_size):\n",
    "        in_j = input[j]\n",
    "        for i in range(0, layer.output_size):\n",
    "            grad = output_grad[i] * in_j\n",
    "            layer.weight_momentum[(j * layer.output_size) + i] = MOMENTUM * layer.weight_momentum[(j * layer.output_size) + i] + lr * grad\n",
    "            layer.weights[(j * layer.output_size) + i] -= layer.weight_momentum[(j * layer.output_size) + i]\n",
    "            if (input_grad):\n",
    "                input_grad[j] += output_grad[i] * layer.weights[(j * layer.output_size) + i]\n",
    "\n",
    "    for i in range(0, layer.output_size):\n",
    "        layer.bias_momentum[i] = MOMENTUM * layer.bias_momentum[i] + lr * output_grad[i]\n",
    "        layer.biases[i] -= layer.bias_momentum[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adb9019d-069d-450c-aa8f-e5fe7a8a3045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net: Network, input, label, lr):\n",
    "    # print(\"train\")\n",
    "    final_output = [0] * OUTPUT_SIZE\n",
    "    hidden_output= [0] * HIDDEN_SIZE\n",
    "    output_grad = [0] * OUTPUT_SIZE\n",
    "    hidden_grad = [0] * HIDDEN_SIZE\n",
    "\n",
    "    forward(net.hidden, input, hidden_output)\n",
    "    forward(net.output, hidden_output, final_output)\n",
    "    final_output = softmax(final_output, OUTPUT_SIZE)\n",
    "\n",
    "    for i in range(0, OUTPUT_SIZE):\n",
    "        output_grad[i] = final_output[i] - (i == label)\n",
    "\n",
    "    backward(net.output, hidden_output, output_grad, hidden_grad, lr)\n",
    "\n",
    "    for i in range(0, HIDDEN_SIZE):\n",
    "        hidden_grad[i] *= 1 if hidden_output[i] > 0 else 0 # ReLU derivative\n",
    "\n",
    "    backward(net.hidden, input, hidden_grad, False, lr)\n",
    "\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6057237-bb49-4426-b26c-a6ba28da4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net: Network, input):\n",
    "    final_output = [0] * OUTPUT_SIZE\n",
    "    hidden_output= [0] * HIDDEN_SIZE\n",
    "\n",
    "    forward(net.hidden, input, hidden_output)\n",
    "    forward(net.output, hidden_output, final_output)\n",
    "    final_output = softmax(final_output, OUTPUT_SIZE)\n",
    "    \n",
    "    max_index = 0\n",
    "    for i in range (1, OUTPUT_SIZE):\n",
    "        if final_output[i] > final_output[max_index]:\n",
    "            max_index = i\n",
    "\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a2e7e8-c55b-4444-a41b-9e0f35314cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__():\n",
    "    print(\"__init__\")\n",
    "    net = Network(INPUT_SIZE, HIDDEN_SIZE, HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    \n",
    "    init_layer(net.hidden, INPUT_SIZE, HIDDEN_SIZE);\n",
    "    init_layer(net.output, HIDDEN_SIZE, OUTPUT_SIZE);\n",
    "\n",
    "    (n_images, rows, cols, images_array) = load_images('./data/train-images.idx3-ubyte', IMAGE_SIZE)\n",
    "    (n_labels, labels_array) = load_labels('./data/train-labels.idx1-ubyte')\n",
    "\n",
    "    data = InputData(images_array, labels_array, n_images)\n",
    "    shuffle_data(data.images, data.labels, data.count)\n",
    "\n",
    "    learning_rate = LEARNING_RATE\n",
    "    img = [0] * INPUT_SIZE\n",
    "\n",
    "    train_size = 200 # int(data.count * TRAIN_SPLIT)\n",
    "    test_size = 100 # int(data.count - train_size)\n",
    "\n",
    "    for epoch in range (0, EPOCHS):\n",
    "        total_loss = 0\n",
    "        for i in range(0, train_size):\n",
    "            for k in range(0, INPUT_SIZE):\n",
    "                # print(i,k)\n",
    "                img[k] = data.images[i * INPUT_SIZE + k] / 255.0\n",
    "\n",
    "            final_output = train(net, img, data.labels[i], learning_rate)\n",
    "            total_loss += -math.log(final_output[data.labels[i]] + 0.0000000001)\n",
    "    \n",
    "        correct = 0\n",
    "        for i in range(train_size, train_size + test_size):\n",
    "            for k in range(0, INPUT_SIZE):\n",
    "                img[k] = data.images[i * INPUT_SIZE + k] / 255.0\n",
    "            if predict(net, img) == data.labels[i]:\n",
    "                correct += 1\n",
    "    \n",
    "        print(\"Epoch {}, Train {}, Test {}, Correct {}, Loss {}\".format(epoch + 1, train_size, test_size, correct, total_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60a8f478-8e66-42ae-8cfc-efb49e041552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__\n",
      "Epoch 1, Train 200, Test 100, Correct 13, Loss 460.6303475586824\n",
      "Epoch 2, Train 200, Test 100, Correct 13, Loss 460.427408753468\n",
      "Epoch 3, Train 200, Test 100, Correct 13, Loss 460.2440283235627\n",
      "Epoch 4, Train 200, Test 100, Correct 13, Loss 460.07977066764454\n",
      "Epoch 5, Train 200, Test 100, Correct 13, Loss 459.9352336133092\n",
      "Epoch 6, Train 200, Test 100, Correct 13, Loss 459.8087397041431\n",
      "Epoch 7, Train 200, Test 100, Correct 13, Loss 459.698731428174\n",
      "Epoch 8, Train 200, Test 100, Correct 13, Loss 459.59791391114726\n",
      "Epoch 9, Train 200, Test 100, Correct 13, Loss 459.51244944805086\n",
      "Epoch 10, Train 200, Test 100, Correct 13, Loss 459.42482896609357\n",
      "Epoch 11, Train 200, Test 100, Correct 13, Loss 459.34383702431745\n",
      "Epoch 12, Train 200, Test 100, Correct 13, Loss 459.26953994258616\n",
      "Epoch 13, Train 200, Test 100, Correct 13, Loss 459.201147667139\n",
      "Epoch 14, Train 200, Test 100, Correct 13, Loss 459.1379899049837\n",
      "Epoch 15, Train 200, Test 100, Correct 13, Loss 459.0794963980546\n",
      "Epoch 16, Train 200, Test 100, Correct 13, Loss 459.02518033854807\n",
      "Epoch 17, Train 200, Test 100, Correct 13, Loss 458.9777978003615\n",
      "Epoch 18, Train 200, Test 100, Correct 13, Loss 458.941296254492\n",
      "Epoch 19, Train 200, Test 100, Correct 13, Loss 458.90045398162823\n",
      "Epoch 20, Train 200, Test 100, Correct 13, Loss 458.8639620327453\n"
     ]
    }
   ],
   "source": [
    "__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a84feb-73ec-4a3e-a75e-939f80691d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86aaedc-e6c3-49ac-a39f-8842ba725eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
